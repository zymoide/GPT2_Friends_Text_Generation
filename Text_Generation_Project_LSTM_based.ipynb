{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation_Project_LSTM_based.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPda0Ftux9omkP+UD1Fq9jE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zymoide/GPT2_Friends_Text_Generation/blob/main/Text_Generation_Project_LSTM_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg6Zl3l56FaS"
      },
      "source": [
        "def read_file(filepath):\n",
        "    \n",
        "    with open(filepath) as f:\n",
        "        str_text = f.read()\n",
        "    \n",
        "    return str_text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11mw9WYH6Iom"
      },
      "source": [
        "read_file(\"/content/Friends_S_1.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBAxS34r6duE"
      },
      "source": [
        "import spacy\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HdRb1bp8V3g"
      },
      "source": [
        "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
        "nlp.max_length = 5198623"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAGTtHuy7NpP"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBF-jHHK8b1c"
      },
      "source": [
        "def separate_punc(doc_text):\n",
        "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmWPlsA58cMq"
      },
      "source": [
        "d = read_file('/content/Friends_S_1.txt')\n",
        "tokens = separate_punc(d)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbVmt32a8vOB"
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkHWv2io8xsL",
        "outputId": "777287e2-d184-4f1b-ace4-49ee820c61ea"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riRY0g8S83fD"
      },
      "source": [
        "# organize into sequences of tokens\n",
        "train_len = 25+1 # 50 training words, then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "    \n",
        "    # Grab train_len# amount of characters\n",
        "    seq = tokens[i-train_len:i]\n",
        "    \n",
        "    # Add to list of sequences\n",
        "    text_sequences.append(seq)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k_qQ2uZP87YV",
        "outputId": "174764b3-2f6c-4b76-cb1f-90dc3a108b56"
      },
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeffthe one where monica gets a new roommate the pilot the uncut version written by marta kauffman david crane transcribed by guineapig additional transcribing by eric'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYP4SdaO89ZA"
      },
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpuQSKBn8-79"
      },
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvqHljmV9Arw",
        "outputId": "a0e64024-ed7f-452a-a837-c79fe7ec9f2a"
      },
      "source": [
        "len(text_sequences)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXQwZy6_9CDe"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft4qPGLW9Dja"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvP-Tzxa9FsC"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl7HtZe_9Ish"
      },
      "source": [
        "tokenizer.index_word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RXZFjNr9Kfp"
      },
      "source": [
        "for i in sequences[0]:\n",
        "    print(f'{i} : {tokenizer.index_word[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI5WyZYW9PoD"
      },
      "source": [
        "tokenizer.word_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwEwWFTp9RQc"
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onIPETWu9UGL",
        "outputId": "8bbc1d49-b365-4336-a2aa-bcbf2e1ee3fd"
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwpgr2Yg9XtX"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3fC8-D99Zuj"
      },
      "source": [
        "sequences = np.array(sequences)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUPOlBT39bJn",
        "outputId": "2cd12f6a-6cc6-446d-9f20-af82b2cefb34"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6121,   71,  137, ..., 6116,   90, 2341],\n",
              "       [  71,  137,   10, ...,   90, 2341, 2342],\n",
              "       [ 137,   10,  220, ..., 2341, 2342,  882],\n",
              "       ...,\n",
              "       [  76,   77,  165, ...,    3,  881,   30],\n",
              "       [  77,  165,    2, ...,  881,   30,  294],\n",
              "       [ 165,    2,  227, ...,   30,  294,  132]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwpd6Uv19cmQ"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc8UeCAl9gA7"
      },
      "source": [
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(550, return_sequences=True))\n",
        "    model.add(LSTM(550))\n",
        "    model.add(Dense(550, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELK3oBHs9k7M"
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXke6Yf99m17"
      },
      "source": [
        "sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNZchA969pWZ"
      },
      "source": [
        "# First 49 words\n",
        "sequences[:,:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNmb5k309rBz",
        "outputId": "95296aeb-9fed-4aec-b976-7b660c21c933"
      },
      "source": [
        "# last Word\n",
        "sequences[:,-1]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2341, 2342,  882, ...,   30,  294,  132])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHhmkO5a9s79"
      },
      "source": [
        "X = sequences[:,:-1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CoMYNIe9u6Y"
      },
      "source": [
        "y = sequences[:,-1]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6cYSo6C9wPP"
      },
      "source": [
        "y = to_categorical(y, num_classes=vocabulary_size+1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91sre-D89y8M"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYSji2g7-KD_"
      },
      "source": [
        "seq_len = X.shape[1]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyCABlDaULMx",
        "outputId": "817369f2-15b5-4d51-f00a-bd412f344fb2"
      },
      "source": [
        "seq_len"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9DexgsrUNSJ",
        "outputId": "c20af285-55a4-42e1-b434-793fe2167091"
      },
      "source": [
        "model = create_model(vocabulary_size+1, seq_len)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 25, 25)            153050    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 25, 550)           1267200   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 550)               2422200   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 550)               303050    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6122)              3373222   \n",
            "=================================================================\n",
            "Total params: 7,518,722\n",
            "Trainable params: 7,518,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtril2CTUQIm"
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcRht_pcUTNs",
        "outputId": "3f9e9756-ab53-4d6e-d773-fa4f0c9142ea"
      },
      "source": [
        "model.fit(X, y, batch_size=128, epochs=100,verbose=1)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "769/769 [==============================] - 40s 28ms/step - loss: 6.4682 - accuracy: 0.0311\n",
            "Epoch 2/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 5.9088 - accuracy: 0.0483\n",
            "Epoch 3/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 5.6650 - accuracy: 0.0671\n",
            "Epoch 4/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 5.4460 - accuracy: 0.0875\n",
            "Epoch 5/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 5.2687 - accuracy: 0.1023\n",
            "Epoch 6/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 5.1109 - accuracy: 0.1132\n",
            "Epoch 7/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.9682 - accuracy: 0.1232\n",
            "Epoch 8/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.9206 - accuracy: 0.1243\n",
            "Epoch 9/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.7751 - accuracy: 0.1345\n",
            "Epoch 10/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.6340 - accuracy: 0.1413\n",
            "Epoch 11/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.5245 - accuracy: 0.1475\n",
            "Epoch 12/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 4.4028 - accuracy: 0.1520\n",
            "Epoch 13/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 4.3049 - accuracy: 0.1552\n",
            "Epoch 14/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 4.1882 - accuracy: 0.1650\n",
            "Epoch 15/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.0898 - accuracy: 0.1715\n",
            "Epoch 16/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.0053 - accuracy: 0.1765\n",
            "Epoch 17/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 4.0254 - accuracy: 0.1763\n",
            "Epoch 18/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.8667 - accuracy: 0.1884\n",
            "Epoch 19/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.7636 - accuracy: 0.2027\n",
            "Epoch 20/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.6643 - accuracy: 0.2143\n",
            "Epoch 21/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.5731 - accuracy: 0.2266\n",
            "Epoch 22/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.4807 - accuracy: 0.2395\n",
            "Epoch 23/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 3.3992 - accuracy: 0.2495\n",
            "Epoch 24/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.3324 - accuracy: 0.2611\n",
            "Epoch 25/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.2413 - accuracy: 0.2735\n",
            "Epoch 26/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.1623 - accuracy: 0.2869\n",
            "Epoch 27/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.0759 - accuracy: 0.3025\n",
            "Epoch 28/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 3.0198 - accuracy: 0.3139\n",
            "Epoch 29/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.9420 - accuracy: 0.3273\n",
            "Epoch 30/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.8536 - accuracy: 0.3413\n",
            "Epoch 31/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.7855 - accuracy: 0.3551\n",
            "Epoch 32/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.7184 - accuracy: 0.3685\n",
            "Epoch 33/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.6435 - accuracy: 0.3790\n",
            "Epoch 34/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.5783 - accuracy: 0.3958\n",
            "Epoch 35/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.5063 - accuracy: 0.4088\n",
            "Epoch 36/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.4230 - accuracy: 0.4243\n",
            "Epoch 37/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.3614 - accuracy: 0.4381\n",
            "Epoch 38/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.2850 - accuracy: 0.4519\n",
            "Epoch 39/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.2032 - accuracy: 0.4702\n",
            "Epoch 40/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.1385 - accuracy: 0.4860\n",
            "Epoch 41/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 2.0597 - accuracy: 0.4991\n",
            "Epoch 42/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.9884 - accuracy: 0.5168\n",
            "Epoch 43/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.9091 - accuracy: 0.5333\n",
            "Epoch 44/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.8286 - accuracy: 0.5509\n",
            "Epoch 45/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.7655 - accuracy: 0.5662\n",
            "Epoch 46/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 1.6843 - accuracy: 0.5864\n",
            "Epoch 47/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.6193 - accuracy: 0.5991\n",
            "Epoch 48/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.5466 - accuracy: 0.6166\n",
            "Epoch 49/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.4725 - accuracy: 0.6336\n",
            "Epoch 50/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.3949 - accuracy: 0.6526\n",
            "Epoch 51/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.3208 - accuracy: 0.6692\n",
            "Epoch 52/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.2634 - accuracy: 0.6859\n",
            "Epoch 53/100\n",
            "769/769 [==============================] - 21s 27ms/step - loss: 1.1895 - accuracy: 0.7018\n",
            "Epoch 54/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 1.1201 - accuracy: 0.7185\n",
            "Epoch 55/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 1.0548 - accuracy: 0.7355\n",
            "Epoch 56/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.9927 - accuracy: 0.7513\n",
            "Epoch 57/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.9373 - accuracy: 0.7647\n",
            "Epoch 58/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.8697 - accuracy: 0.7810\n",
            "Epoch 59/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.8094 - accuracy: 0.7979\n",
            "Epoch 60/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.7518 - accuracy: 0.8134\n",
            "Epoch 61/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.7022 - accuracy: 0.8239\n",
            "Epoch 62/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.6473 - accuracy: 0.8410\n",
            "Epoch 63/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.6025 - accuracy: 0.8531\n",
            "Epoch 64/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.5570 - accuracy: 0.8637\n",
            "Epoch 65/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.5048 - accuracy: 0.8785\n",
            "Epoch 66/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.4809 - accuracy: 0.8839\n",
            "Epoch 67/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.4267 - accuracy: 0.8980\n",
            "Epoch 68/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.4050 - accuracy: 0.9020\n",
            "Epoch 69/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.3774 - accuracy: 0.9104\n",
            "Epoch 70/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.3401 - accuracy: 0.9199\n",
            "Epoch 71/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.3298 - accuracy: 0.9202\n",
            "Epoch 72/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2912 - accuracy: 0.9326\n",
            "Epoch 73/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2815 - accuracy: 0.9338\n",
            "Epoch 74/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2602 - accuracy: 0.9394\n",
            "Epoch 75/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2393 - accuracy: 0.9445\n",
            "Epoch 76/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2339 - accuracy: 0.9445\n",
            "Epoch 77/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2215 - accuracy: 0.9481\n",
            "Epoch 78/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.2167 - accuracy: 0.9468\n",
            "Epoch 79/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1879 - accuracy: 0.9566\n",
            "Epoch 80/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1849 - accuracy: 0.9557\n",
            "Epoch 81/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1850 - accuracy: 0.9551\n",
            "Epoch 82/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1635 - accuracy: 0.9622\n",
            "Epoch 83/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1562 - accuracy: 0.9633\n",
            "Epoch 84/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1666 - accuracy: 0.9595\n",
            "Epoch 85/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1421 - accuracy: 0.9669\n",
            "Epoch 86/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1551 - accuracy: 0.9617\n",
            "Epoch 87/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1523 - accuracy: 0.9622\n",
            "Epoch 88/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1231 - accuracy: 0.9706\n",
            "Epoch 89/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1389 - accuracy: 0.9647\n",
            "Epoch 90/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1508 - accuracy: 0.9607\n",
            "Epoch 91/100\n",
            "769/769 [==============================] - 22s 28ms/step - loss: 0.1380 - accuracy: 0.9651\n",
            "Epoch 92/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1199 - accuracy: 0.9696\n",
            "Epoch 93/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1386 - accuracy: 0.9634\n",
            "Epoch 94/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1229 - accuracy: 0.9684\n",
            "Epoch 95/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1200 - accuracy: 0.9686\n",
            "Epoch 96/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1556 - accuracy: 0.9560\n",
            "Epoch 97/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.0827 - accuracy: 0.9809\n",
            "Epoch 98/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1045 - accuracy: 0.9733\n",
            "Epoch 99/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1636 - accuracy: 0.9519\n",
            "Epoch 100/100\n",
            "769/769 [==============================] - 21s 28ms/step - loss: 0.1009 - accuracy: 0.9736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5e3b8a7750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mntn_lYQUVCb"
      },
      "source": [
        "# save the model to file\n",
        "model.save('epochBIG.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('epochBIG', 'wb'))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJtP3gLOcm-e"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNfcsKdDcro-"
      },
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "    '''\n",
        "    \n",
        "    # Final Output\n",
        "    output_text = []\n",
        "    \n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "    \n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "        \n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        \n",
        "        # Pad sequences to our trained rate (50 words in the video)\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        \n",
        "        # Predict Class Probabilities for each word\n",
        "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
        "        \n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind] \n",
        "        \n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "        \n",
        "        output_text.append(pred_word)\n",
        "        \n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AOdv2uBcttp",
        "outputId": "f1a56470-2ddf-404b-d379-a8a529a2d975"
      },
      "source": [
        "text_sequences[0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\ufeffthe',\n",
              " 'one',\n",
              " 'where',\n",
              " 'monica',\n",
              " 'gets',\n",
              " 'a',\n",
              " 'new',\n",
              " 'roommate',\n",
              " 'the',\n",
              " 'pilot',\n",
              " 'the',\n",
              " 'uncut',\n",
              " 'version',\n",
              " 'written',\n",
              " 'by',\n",
              " 'marta',\n",
              " 'kauffman',\n",
              " 'david',\n",
              " 'crane',\n",
              " 'transcribed',\n",
              " 'by',\n",
              " 'guineapig',\n",
              " 'additional',\n",
              " 'transcribing',\n",
              " 'by',\n",
              " 'eric']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEP4sHFAcv8j"
      },
      "source": [
        "import random\n",
        "#random.seed(101)\n",
        "random_pick = random.randint(0,len(text_sequences))\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmPEfk-EczgO"
      },
      "source": [
        "#random_seed_text = text_sequences[random_pick]\n",
        "random_seed_text = text_sequences[random_pick] #continuing my try\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDL0ci3wc1-N",
        "outputId": "081a5aa1-54a8-4c53-e07e-11d0456ae002"
      },
      "source": [
        "random_seed_text"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['they',\n",
              " 'both',\n",
              " 'leave',\n",
              " 'just',\n",
              " 'as',\n",
              " 'rachel',\n",
              " 'enters',\n",
              " 'the',\n",
              " 'room',\n",
              " 'holding',\n",
              " 'a',\n",
              " 'cup',\n",
              " 'rachel',\n",
              " 'hi',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'you',\n",
              " 'might',\n",
              " 'like',\n",
              " 'some',\n",
              " 'ice',\n",
              " 'chips',\n",
              " 'carol',\n",
              " 'thanks',\n",
              " 'rachel',\n",
              " 'and']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AexkPMtXc3uN"
      },
      "source": [
        "seed_text = ' '.join(random_seed_text)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xEUx88rSc7Hs",
        "outputId": "21cbf72c-2d85-4fc1-9d38-8acae2df3e4f"
      },
      "source": [
        "seed_text"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'they both leave just as rachel enters the room holding a cup rachel hi i thought you might like some ice chips carol thanks rachel and'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "5y5etr9tc82P",
        "outputId": "1110d5a8-3518-4d1f-b694-27be81e29d63"
      },
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"if you need anything else i—(notices joey so what 's with you 're gon na be alright uh chandler if nobody was your wenus she has all big kind of insecure and not us they know no one scene monica and rachel 's phoebe is smoking at the phone rachel\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D94pSvX5c_Tj"
      },
      "source": [
        "full_text = read_file('/content/Friends_S_1.txt')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAlqUnoAdV9Q"
      },
      "source": [
        "for i,word in enumerate(full_text.split()):\n",
        "    if word == 'inkling':\n",
        "        print(' '.join(full_text.split()[i-20:i+20]))\n",
        "        print('\\n')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0bNhz0FdWqa"
      },
      "source": [
        "### Code taken (and modified) from Mr J Portilla. ###"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}